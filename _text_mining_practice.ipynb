{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMvNgU+dEqsTKiMY+plm1DN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhyeon03/study_ML_/blob/main/_text_mining_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. 텍스트 분석"
      ],
      "metadata": {
        "id": "5Bz6ne5h5ikN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 텍스트 분류\n",
        "  - 문서가 특정 분류 또는 카테고리에 속하는 것을 예측하는 기법\n",
        "* 감성 분석\n",
        "  - 텍스트에서 나타나는 감정/판단/믿음/의견/기분 등의 주관적 요소를 분석하는 기법\n",
        "* 텍스트 요약\n",
        "  - 텍스트 내에서 중요한 주제나 중심 사상을 추출하는 기법\n",
        "* 텍스트 군집화와 유사도 측정\n",
        "  - 비슷한 유형의 문서에 대해서 군집화를 수행하는 기법\n",
        "  - 텍스트 분류를 비지도 학습으로 수행하는 방법의 일환\n",
        "  - 유사도 측정 역시 문서들간의 유사도를 측정해 비슷한 문서끼리 모을 수 있는 방법이다."
      ],
      "metadata": {
        "id": "_8-RedxG6G2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S10X2_J4YNV"
      },
      "outputs": [],
      "source": [
        "# 텍스트 분석은 비정형 데이터인 텍스트를 분석하는 것이다. 지금까지 ML모델은 주어진 정형 데이터기반에서 모델을 수립하고 예측을 수행했다.\n",
        "# 텍스트를 머신어닝에 적용하기 위해서는 비정형 텍스트 데이터를 어떻게 피처 형태로 추출하고 추출된 피처에 의미있는 값을 부여하는가 하는것이\n",
        "# 매우 중요한 요소이다.\n",
        "# 텍스트를 word 기반의 다수의 피처로 추출하고 이 피처에 단어 빈도수와 같은 숫자 값을 부여하면 텍스트는 단어의 조합인 벡터값으로 표현될 수 있는데\n",
        "# 이렇게 변환하는 것을 피처벡터화, 피처추출이라고 한다. 대표적으로 BOW와 Word2Vec 방법이 있다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 분석 수행 프로세스\n",
        "# step 1\n",
        "# 텍스트 사전 준비작업(텍스트 전처리) : 텍스트를 피처로 만들기 전에 미리 클렌징, 대/소문자 변경, 특수문자 삭제 등의 클렌징 작업, 단어등의 토큰화 작업, 의미없는 단어 제거 작업\n",
        "#                               어근 추출 등의 텍스트 정규화 작업을 수행하는 것을 통칭한다.\n",
        "# step 2\n",
        "# 피처 벡터화/추출 : 사전 준비 작업으로 가공된 텍스트에서 피처를 추출하고 여기에 벡터 값을 할당한다. 대표적인 방법인 방법은 BOW와 Word2Vec이 있으며, BOW는 대표적으로 Count기반과 TF-IDF 기반 벡터화가 있다.\n",
        "# step 3\n",
        "# ML 모델 수립 및 학습/예측/평가 : 피처 벡터화된 데이터 세트에 ML 모델을 적용해 학습/예측 및 평가를 수행한다."
      ],
      "metadata": {
        "id": "-l23oeyS9t4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런은 머신러닝 위주 라이브러리여서 NLP를 위한 다양한라이브러리를 가지고 있지않다.\n",
        "# 더 다양한 텍스트 부넉이 적용돼야하는 경우 보통은 NLTK/Gensim/SpaCy와 같은 NLP 전용 패키지와 함께 결합해 어플리케이션을 작성하는 경우가 많다."
      ],
      "metadata": {
        "id": "TqK1_a99-zgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.텍스트 사전 준비 작업(텍스트 전처리) - 텍스트 정규화"
      ],
      "metadata": {
        "id": "NRshijHj_O-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 클렌징\n",
        "  - 불필요한 문자, 기호 등을 사전에 제거하는 작업 ex.HTML, XML 태그나 특정기호\n",
        "* 토큰화\n",
        "  - 문장 토큰화 vs 단어 토큰화\n",
        "* 필터링/스톱워드제거/철자수정\n",
        "* stemming\n",
        "* Lemmatization\n",
        "\n"
      ],
      "metadata": {
        "id": "zlcRki-5_WuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1.문장 토큰화"
      ],
      "metadata": {
        "id": "AqPKU4POEg-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')  # punkt만 정확히 다운로드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPRcy3z7F52N",
        "outputId": "420140ac-583f-4093-b07d-c391f83fb3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize\n",
        "\n",
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room.  \\\n",
        "              You can see it out your window or on your television. \\\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\n",
        "sentences = sent_tokenize(text=text_sample)\n",
        "print(type(sentences),len(sentences))\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTjP5ItX_MpO",
        "outputId": "d78931a5-5d77-4c5e-bcdd-32f7b0d56c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-2.단어 토큰화"
      ],
      "metadata": {
        "id": "fC1RF1-1EoNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
        "words = word_tokenize(sentence)\n",
        "print(type(words), len(words))\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl6Uom9uEqDQ",
        "outputId": "b9d0ccb6-103f-4653-eea4-1114a52a4997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 15\n",
            "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-3. 여러 문장들에 대한 단어 토큰화"
      ],
      "metadata": {
        "id": "egyVgZFPEr5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "#여러개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화 만드는 함수 생성\n",
        "def tokenize_text(text):\n",
        "\n",
        "    # 문장별로 분리 토큰\n",
        "    sentences = sent_tokenize(text)\n",
        "    # 분리된 문장별 단어 토큰화\n",
        "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
        "    return word_tokens\n",
        "\n",
        "#여러 문장들에 대해 문장별 단어 토큰화 수행.\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV6K5VgkEu1U",
        "outputId": "d7b711e7-a10a-440a-adbe-addc76da547f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-4.n-gram"
      ],
      "metadata": {
        "id": "u-p1OBSjGFlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
        "words = word_tokenize(sentence)\n",
        "\n",
        "all_ngrams = ngrams(words, 2)\n",
        "ngrams = [ngram for ngram in all_ngrams]\n",
        "print(ngrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4wxHzHQGgPj",
        "outputId": "fcf52633-f3e9-4e16-edaa-dcf9f12dc783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'Matrix'), ('Matrix', 'is'), ('is', 'everywhere'), ('everywhere', 'its'), ('its', 'all'), ('all', 'around'), ('around', 'us'), ('us', ','), (',', 'here'), ('here', 'even'), ('even', 'in'), ('in', 'this'), ('this', 'room'), ('room', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-5.Stopwords 제거"
      ],
      "metadata": {
        "id": "z5sgjr8uGIHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afxTDkHXGkEZ",
        "outputId": "30489c43-82db-4ce0-8d76-20bdf34fe276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('영어 stop words 갯수:',len(nltk.corpus.stopwords.words('english')))\n",
        "print(nltk.corpus.stopwords.words('english')[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5D48REhGmCf",
        "outputId": "10f496b1-2ef1-4a5e-c8ad-693918145cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 stop words 갯수: 198\n",
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "all_tokens = []\n",
        "# 위 예제의 3개의 문장별로 얻은 word_tokens list 에 대해 stop word 제거 Loop\n",
        "for sentence in word_tokens:\n",
        "    filtered_words=[]\n",
        "    # 개별 문장별로 tokenize된 sentence list에 대해 stop word 제거 Loop\n",
        "    for word in sentence:\n",
        "        #소문자로 모두 변환합니다.\n",
        "        word = word.lower()\n",
        "        # tokenize 된 개별 word가 stop words 들의 단어에 포함되지 않으면 word_tokens에 추가\n",
        "        if word not in stopwords:\n",
        "            filtered_words.append(word)\n",
        "    all_tokens.append(filtered_words)\n",
        "\n",
        "print(all_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsN5S8kHGok0",
        "outputId": "3926038d-c58e-4db9-9b78-0d339ebf48ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-6.Stemming과 Lemmatization"
      ],
      "metadata": {
        "id": "8FFw9LqvGOz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOq9nzl4Gq9j",
        "outputId": "85735b00-4fb9-4563-900f-05796337f7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work work work\n",
            "amus amus amus\n",
            "happy happiest\n",
            "fant fanciest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemma = WordNetLemmatizer()\n",
        "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))\n",
        "print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n",
        "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWQZwd18GsVk",
        "outputId": "bc6b9119-743d-49d0-a562-8fbefe302564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amuse amuse amuse\n",
            "happy happy\n",
            "fancy fancy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Bag of Words - BOW"
      ],
      "metadata": {
        "id": "56VJZNf1yErA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words 모델은 문서가 가지는 모든 단어를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도값을 부여해 피처 값을 추출하는 모델이다.\n",
        "# step1\n",
        "# 문장 1과 문장 2에 있는 모든 단어에서 중복을 제거하고 각 단어를 칼럼 형태로 나열한다. 그러고 나서 각 단어에 고유의 인덱스를 다음과 같이 부여한다.\n",
        "# step2\n",
        "# 개별 문장에서 해당 단어가 나타나는 횟수를 각 단어에 기재한다. 예를 들어 base-ball은 문장1,2에서 총 2번 나타나며, daughter는 문장1에서만 1번 나타남\n",
        "\n",
        "# 단점\n",
        "# 문맥 의미 반영 부족 - 단어의 순서 고려 X\n",
        "# 희소 행렬 문제\n",
        "\n",
        "# BOW의 피처 벡터화 방식\n",
        "# 1. 카운트 기반의 벡터화\n",
        "#    단어 피처에 값을 부여할 때 각 문서에서 해당 단어가 나타나는 횟수, 즉 count를 부여하는 경우를 카운터 벡터화라고 한다.\n",
        "#    카운트 벡터화에서는 카운트 값이 높을수록 중요한 단어로 인식된다.\n",
        "#    그러나 카운트만 부여할 경우 그 문서의 특징을 나타내기보다는 언어의 특성상 문장에서 자주 사용될 수 밖에 없는 단어까지 높은 값을 부여한다.\n",
        "# 2. TF-IDE 기반의 벡터화\n",
        "#    자주 나타나는 단어에 높은 가중치를 주되, 모든 문서에서 전반적으로 자주 나타나는 단어에 대해서는 페널티를 주는 방식으로 값을 부여한다.\n",
        "#    - 만일 어떤 문서에서 특정단어가 자주 나타나면 그 단어는 해당 문서를 특징짓는 중요단어일 수 있다. 하지만 그 단어가 다른 문서에서도 자주 나타나는 단어라면\n",
        "#      해당 단어는 언어 특성상 범용적으로 자주 사용되는 단어일 가능성이 높다.\n",
        "# 텍스트가 길고, 문서의 개수가 많을 경우 TF-IDF 방식을 사용하는 것이 더 좋은 예측성능을 보장할 수 있다."
      ],
      "metadata": {
        "id": "ZelRRjQRyK2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런 CountVectorizer 테스트\n",
        "text_sample_01 = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
        "                  You can see it out your window or on your television. \\\n",
        "                  You feel it when you go to work, or go to church or pay your taxes.'\n",
        "text_sample_02 = 'You take the blue pill and the story ends.  You wake in your bed and you believe whatever you want to believe\\\n",
        "                  You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'\n",
        "text=[]\n",
        "text.append(text_sample_01); text.append(text_sample_02)\n",
        "print(text,\"\\n\", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd5jIreR0krm",
        "outputId": "a684df75-247b-4efc-9551-1bf555fb5b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Matrix is everywhere its all around us, here even in this room.                   You can see it out your window or on your television.                   You feel it when you go to work, or go to church or pay your taxes.', 'You take the blue pill and the story ends.  You wake in your bed and you believe whatever you want to believe                  You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'] \n",
            " 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer객체 생성 후 fit(), transform()으로 텍스트에 대한 feature vectorization 수행\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Count Vectorization으로 feature extraction 변환 수행.\n",
        "cnt_vect = CountVectorizer()\n",
        "cnt_vect.fit(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "L-7OVIJV06I-",
        "outputId": "15233e5e-b109-4f2e-a04e-f2d63abd5ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ftr_vect = cnt_vect.transform(text)"
      ],
      "metadata": {
        "id": "sZ9KHzk609As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처 벡터화 후 데이터 유형 및 여러 속성 확인\n",
        "print(type(ftr_vect), ftr_vect.shape)\n",
        "print(ftr_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81alrsg00_Pa",
        "outputId": "0439de9c-7bbf-4dfc-8edf-a51b00368927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'> (2, 51)\n",
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 56 stored elements and shape (2, 51)>\n",
            "  Coords\tValues\n",
            "  (0, 0)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 13)\t2\n",
            "  (0, 15)\t1\n",
            "  (0, 18)\t1\n",
            "  (0, 19)\t1\n",
            "  (0, 20)\t2\n",
            "  (0, 21)\t1\n",
            "  (0, 22)\t1\n",
            "  (0, 23)\t1\n",
            "  (0, 24)\t3\n",
            "  (0, 25)\t1\n",
            "  (0, 26)\t1\n",
            "  (0, 30)\t1\n",
            "  (0, 31)\t1\n",
            "  (0, 36)\t1\n",
            "  (0, 37)\t1\n",
            "  (0, 38)\t1\n",
            "  (0, 39)\t1\n",
            "  (0, 40)\t2\n",
            "  :\t:\n",
            "  (1, 1)\t4\n",
            "  (1, 3)\t1\n",
            "  (1, 4)\t2\n",
            "  (1, 5)\t1\n",
            "  (1, 8)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 16)\t1\n",
            "  (1, 17)\t1\n",
            "  (1, 18)\t2\n",
            "  (1, 27)\t2\n",
            "  (1, 28)\t1\n",
            "  (1, 29)\t1\n",
            "  (1, 32)\t1\n",
            "  (1, 33)\t1\n",
            "  (1, 34)\t1\n",
            "  (1, 35)\t2\n",
            "  (1, 38)\t4\n",
            "  (1, 40)\t1\n",
            "  (1, 42)\t1\n",
            "  (1, 43)\t1\n",
            "  (1, 44)\t1\n",
            "  (1, 47)\t1\n",
            "  (1, 49)\t7\n",
            "  (1, 50)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnt_vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHGWxRPm1D4k",
        "outputId": "dd759b57-1d1a-4c5b-ddb1-ac0e1f5d7962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 38, 'matrix': 22, 'is': 19, 'everywhere': 11, 'its': 21, 'all': 0, 'around': 2, 'us': 41, 'here': 15, 'even': 10, 'in': 18, 'this': 39, 'room': 30, 'you': 49, 'can': 6, 'see': 31, 'it': 20, 'out': 25, 'your': 50, 'window': 46, 'or': 24, 'on': 23, 'television': 37, 'feel': 12, 'when': 45, 'go': 13, 'to': 40, 'work': 48, 'church': 7, 'pay': 26, 'taxes': 36, 'take': 35, 'blue': 5, 'pill': 27, 'and': 1, 'story': 34, 'ends': 9, 'wake': 42, 'bed': 3, 'believe': 4, 'whatever': 44, 'want': 43, 'red': 29, 'stay': 33, 'wonderland': 47, 'show': 32, 'how': 17, 'deep': 8, 'rabbit': 28, 'hole': 16, 'goes': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt_vect = CountVectorizer(max_features=5, stop_words='english')\n",
        "cnt_vect.fit(text)\n",
        "ftr_vect = cnt_vect.transform(text)\n",
        "print(type(ftr_vect), ftr_vect.shape)\n",
        "print(cnt_vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9gALXRk1FqS",
        "outputId": "6a7538c7-5977-4486-ccaa-69921f46fe98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'> (2, 5)\n",
            "{'blue': np.int64(2), 'pill': np.int64(4), 'bed': np.int64(0), 'believe': np.int64(1), 'deep': np.int64(3)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ngram_range 확인\n",
        "cnt_vect = CountVectorizer(ngram_range=(1,3))\n",
        "cnt_vect.fit(text)\n",
        "ftr_vect = cnt_vect.transform(text)\n",
        "print(type(ftr_vect), ftr_vect.shape)\n",
        "print(cnt_vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWejUyN-1Hd6",
        "outputId": "6b249922-62b1-43c8-847a-a1e188367b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'> (2, 201)\n",
            "{'the': 129, 'matrix': 77, 'is': 66, 'everywhere': 40, 'its': 74, 'all': 0, 'around': 11, 'us': 150, 'here': 51, 'even': 37, 'in': 59, 'this': 140, 'room': 106, 'you': 174, 'can': 25, 'see': 109, 'it': 69, 'out': 90, 'your': 193, 'window': 165, 'or': 83, 'on': 80, 'television': 126, 'feel': 43, 'when': 162, 'go': 46, 'to': 143, 'work': 171, 'church': 28, 'pay': 93, 'taxes': 125, 'the matrix': 132, 'matrix is': 78, 'is everywhere': 67, 'everywhere its': 41, 'its all': 75, 'all around': 1, 'around us': 12, 'us here': 151, 'here even': 52, 'even in': 38, 'in this': 60, 'this room': 141, 'room you': 107, 'you can': 177, 'can see': 26, 'see it': 110, 'it out': 70, 'out your': 91, 'your window': 199, 'window or': 166, 'or on': 86, 'on your': 81, 'your television': 197, 'television you': 127, 'you feel': 179, 'feel it': 44, 'it when': 72, 'when you': 163, 'you go': 181, 'go to': 47, 'to work': 148, 'work or': 172, 'or go': 84, 'to church': 146, 'church or': 29, 'or pay': 88, 'pay your': 94, 'your taxes': 196, 'the matrix is': 133, 'matrix is everywhere': 79, 'is everywhere its': 68, 'everywhere its all': 42, 'its all around': 76, 'all around us': 2, 'around us here': 13, 'us here even': 152, 'here even in': 53, 'even in this': 39, 'in this room': 61, 'this room you': 142, 'room you can': 108, 'you can see': 178, 'can see it': 27, 'see it out': 111, 'it out your': 71, 'out your window': 92, 'your window or': 200, 'window or on': 167, 'or on your': 87, 'on your television': 82, 'your television you': 198, 'television you feel': 128, 'you feel it': 180, 'feel it when': 45, 'it when you': 73, 'when you go': 164, 'you go to': 182, 'go to work': 49, 'to work or': 149, 'work or go': 173, 'or go to': 85, 'go to church': 48, 'to church or': 147, 'church or pay': 30, 'or pay your': 89, 'pay your taxes': 95, 'take': 121, 'blue': 22, 'pill': 96, 'and': 3, 'story': 118, 'ends': 34, 'wake': 153, 'bed': 14, 'believe': 17, 'whatever': 159, 'want': 156, 'red': 103, 'stay': 115, 'wonderland': 168, 'show': 112, 'how': 56, 'deep': 31, 'rabbit': 100, 'hole': 54, 'goes': 50, 'you take': 187, 'take the': 122, 'the blue': 130, 'blue pill': 23, 'pill and': 97, 'and the': 6, 'the story': 138, 'story ends': 119, 'ends you': 35, 'you wake': 189, 'wake in': 154, 'in your': 64, 'your bed': 194, 'bed and': 15, 'and you': 8, 'you believe': 175, 'believe whatever': 18, 'whatever you': 160, 'you want': 191, 'want to': 157, 'to believe': 144, 'believe you': 20, 'the red': 136, 'red pill': 104, 'you stay': 185, 'stay in': 116, 'in wonderland': 62, 'wonderland and': 169, 'and show': 4, 'show you': 113, 'you how': 183, 'how deep': 57, 'deep the': 32, 'the rabbit': 134, 'rabbit hole': 101, 'hole goes': 55, 'you take the': 188, 'take the blue': 123, 'the blue pill': 131, 'blue pill and': 24, 'pill and the': 98, 'and the story': 7, 'the story ends': 139, 'story ends you': 120, 'ends you wake': 36, 'you wake in': 190, 'wake in your': 155, 'in your bed': 65, 'your bed and': 195, 'bed and you': 16, 'and you believe': 9, 'you believe whatever': 176, 'believe whatever you': 19, 'whatever you want': 161, 'you want to': 192, 'want to believe': 158, 'to believe you': 145, 'believe you take': 21, 'take the red': 124, 'the red pill': 137, 'red pill and': 105, 'pill and you': 99, 'and you stay': 10, 'you stay in': 186, 'stay in wonderland': 117, 'in wonderland and': 63, 'wonderland and show': 170, 'and show you': 5, 'show you how': 114, 'you how deep': 184, 'how deep the': 58, 'deep the rabbit': 33, 'the rabbit hole': 135, 'rabbit hole goes': 102}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3-1.희소 행렬 - COO 형식"
      ],
      "metadata": {
        "id": "vSHz45dp2dM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0이 아닌 데이터만 별도의 데이터 배열에 저장하고, 그 데이터가 가르키는 행과 열의 위치를 별도의 배열로 저장하는 방식\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "dense = np.array( [ [ 3, 0, 1 ],\n",
        "                    [0, 2, 0 ] ] )"
      ],
      "metadata": {
        "id": "57mKpapS2gdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "# 0 이 아닌 데이터 추출\n",
        "data = np.array([3,1,2])\n",
        "\n",
        "# 행 위치와 열 위치를 각각 array로 생성\n",
        "row_pos = np.array([0,0,1])\n",
        "col_pos = np.array([0,2,1])\n",
        "\n",
        "# sparse 패키지의 coo_matrix를 이용하여 COO 형식으로 희소 행렬 생성\n",
        "sparse_coo = sparse.coo_matrix((data, (row_pos,col_pos)))"
      ],
      "metadata": {
        "id": "SKwklQFy2j0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(sparse_coo))\n",
        "print(sparse_coo)\n",
        "dense01=sparse_coo.toarray()\n",
        "print(type(dense01),\"\\n\", dense01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP9eD5WN2kxv",
        "outputId": "79cab093-2659-4578-a704-6293c9043a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._coo.coo_matrix'>\n",
            "<COOrdinate sparse matrix of dtype 'int64'\n",
            "\twith 3 stored elements and shape (2, 3)>\n",
            "  Coords\tValues\n",
            "  (0, 0)\t3\n",
            "  (0, 2)\t1\n",
            "  (1, 1)\t2\n",
            "<class 'numpy.ndarray'> \n",
            " [[3 0 1]\n",
            " [0 2 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3-2.희소 행렬 – CSR 형식"
      ],
      "metadata": {
        "id": "ywBJMOQj2m2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coo형식이 행과 열의 위치를 나타내기 위해서 반복적인 위치 데이터를 사용해야 하는 문제점을 해결한 방식\n",
        "\n",
        "from scipy import sparse\n",
        "\n",
        "dense2 = np.array([[0,0,1,0,0,5],\n",
        "             [1,4,0,3,2,5],\n",
        "             [0,6,0,3,0,0],\n",
        "             [2,0,0,0,0,0],\n",
        "             [0,0,0,7,0,8],\n",
        "             [1,0,0,0,0,0]])\n",
        "\n",
        "# 0 이 아닌 데이터 추출\n",
        "data2 = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n",
        "\n",
        "# 행 위치와 열 위치를 각각 array로 생성\n",
        "row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])\n",
        "col_pos = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])\n",
        "\n",
        "# COO 형식으로 변환\n",
        "sparse_coo = sparse.coo_matrix((data2, (row_pos,col_pos)))\n",
        "\n",
        "# 행 위치 배열의 고유한 값들의 시작 위치 인덱스를 배열로 생성\n",
        "row_pos_ind = np.array([0, 2, 7, 9, 10, 12, 13])\n",
        "\n",
        "# CSR 형식으로 변환\n",
        "sparse_csr = sparse.csr_matrix((data2, col_pos, row_pos_ind))\n",
        "\n",
        "print('COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
        "print(sparse_coo.toarray())\n",
        "print('CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
        "print(sparse_csr.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv9wFsTP2pCn",
        "outputId": "ed000dc3-b319-4069-efaa-03324a5c64ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
            "[[0 0 1 0 0 5]\n",
            " [1 4 0 3 2 5]\n",
            " [0 6 0 3 0 0]\n",
            " [2 0 0 0 0 0]\n",
            " [0 0 0 7 0 8]\n",
            " [1 0 0 0 0 0]]\n",
            "CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
            "[[0 0 1 0 0 5]\n",
            " [1 4 0 3 2 5]\n",
            " [0 6 0 3 0 0]\n",
            " [2 0 0 0 0 0]\n",
            " [0 0 0 7 0 8]\n",
            " [1 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sparse_csr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olLpUThS2uT-",
        "outputId": "a0818223-54eb-4fe6-ab43-f12f35b5fd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 13 stored elements and shape (6, 6)>\n",
            "  Coords\tValues\n",
            "  (0, 2)\t1\n",
            "  (0, 5)\t5\n",
            "  (1, 0)\t1\n",
            "  (1, 1)\t4\n",
            "  (1, 3)\t3\n",
            "  (1, 4)\t2\n",
            "  (1, 5)\t5\n",
            "  (2, 1)\t6\n",
            "  (2, 3)\t3\n",
            "  (3, 0)\t2\n",
            "  (4, 3)\t7\n",
            "  (4, 5)\t8\n",
            "  (5, 0)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense3 = np.array([[0,0,1,0,0,5],\n",
        "             [1,4,0,3,2,5],\n",
        "             [0,6,0,3,0,0],\n",
        "             [2,0,0,0,0,0],\n",
        "             [0,0,0,7,0,8],\n",
        "             [1,0,0,0,0,0]])\n",
        "\n",
        "coo = sparse.coo_matrix(dense3)\n",
        "csr = sparse.csr_matrix(dense3)"
      ],
      "metadata": {
        "id": "umwch7-A2wYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.텍스트 분류 실습 - 20 뉴스그룹 분류"
      ],
      "metadata": {
        "id": "vJN-Ml90tfMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4-1. 텍스트 정규화"
      ],
      "metadata": {
        "id": "h0uUP1JRuTqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "news_data = fetch_20newsgroups(subset='all',random_state=156)"
      ],
      "metadata": {
        "id": "7m1_VLwutjUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-IewXXduq54",
        "outputId": "098ad31c-9601-4268-d7df-b7a26dfcc28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('target 클래스의 값과 분포도 \\n', pd.Series(news_data.target).value_counts().sort_index())\n",
        "print('target 클래스의 이름들 \\n', news_data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWdbRhTfu-ZQ",
        "outputId": "3852addb-206b-4bee-de51-a725371df5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 클래스의 값과 분포도 \n",
            " 0     799\n",
            "1     973\n",
            "2     985\n",
            "3     982\n",
            "4     963\n",
            "5     988\n",
            "6     975\n",
            "7     990\n",
            "8     996\n",
            "9     994\n",
            "10    999\n",
            "11    991\n",
            "12    984\n",
            "13    990\n",
            "14    987\n",
            "15    997\n",
            "16    910\n",
            "17    940\n",
            "18    775\n",
            "19    628\n",
            "Name: count, dtype: int64\n",
            "target 클래스의 이름들 \n",
            " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_data.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8bng-8dvhNE",
        "outputId": "33f69b97-3b86-4c25-d55d-a45dfe46de79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
            "Subject: Re: Observation re: helmets\n",
            "Organization: Sun Microsystems, RTP, NC\n",
            "Lines: 21\n",
            "Distribution: world\n",
            "Reply-To: egreen@east.sun.com\n",
            "NNTP-Posting-Host: laser.east.sun.com\n",
            "\n",
            "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
            "> \n",
            "> The question for the day is re: passenger helmets, if you don't know for \n",
            ">certain who's gonna ride with you (like say you meet them at a .... church \n",
            ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
            ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
            ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
            ">passenger? \n",
            "\n",
            "If your primary concern is protecting the passenger in the event of a\n",
            "crash, have him or her fitted for a helmet that is their size.  If your\n",
            "primary concern is complying with stupid helmet laws, carry a real big\n",
            "spare (you can put a big or small head in a big helmet, but not in a\n",
            "small one).\n",
            "\n",
            "---\n",
            "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
            "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
            "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
            " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 내용을 제와하고 제목등의 다른 정보는 제거한다. 왜냐하면 제목과 소속, 이메일 주소등의 헤더와 푸더 정보들은\n",
        "# 뉴스그룹 분류의 Target 클래스 값과 유사한 데이터를 가지고 있는 경우가 많기때문이다.\n",
        "# 이 퍼처들을 포함하게 되면 왠만한 ML 알고리즘을 적용해도 상당히 높은 예측성능을 나타낸다.\n",
        "# 따라서 이들 헤더와 푸더 정보를 포함하는 것은 이 장에서 수행하려는 텍스트 분석의 의도를 벗어나기에 순수한 텍스트만으로 구성된\n",
        "# 기사 내용으로 어떤 뉴스그룹에 속하는지 분류한다.\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# subset = 'train'으로 학습용 데이터만 추출, remove=('headers','footers','quotes')로 내용만 추출\n",
        "train_news = fetch_20newsgroups(subset='train', remove=('headers','footers','quotes'), random_state=156)\n",
        "X_train = train_news.data\n",
        "y_train = train_news.target\n",
        "\n",
        "# subset = 'test'으로 테스트만 추출, remove=('headers','footers','quotes')로 내용만 추출\n",
        "test_news = fetch_20newsgroups(subset='test', remove=('headers','footers','quotes'), random_state=156)\n",
        "X_test = test_news.data\n",
        "y_test = test_news.target\n",
        "print('학습 데이터 크기 {0}, 테스트 데이터 크기 {1}'.format(len(train_news.data), len(test_news.data)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwGsvtdDvzUI",
        "outputId": "846adb6c-da77-4c27-f856-16a8b1b2cdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 크기 11314, 테스트 데이터 크기 7532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4-2. 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가"
      ],
      "metadata": {
        "id": "ax8AaOzZysWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트데이터에서 CountVectorizer를 적용할 때는 반드시 학습 데이터를 이용해 fit()이 수행된 CountVectorizer 객체를\n",
        "# 이용해 테스트 데이터를 변환해야 한다는 것이다. 그래야만 학습시 설정된 CountVertorizer의 피처 개수와 테스트 데이터를 CountVectorizer로 변횐할\n",
        "# 피처 개수가 같아진다.\n",
        "# 테스트 데이터의 피처 벡터화 시 fit_transform()을 사용하면 안 된다는 점도 유의해야한다.\n",
        "# CountVectorizer.fit_transform(테스트 데이터)을 테스트 데이터 세트에 적용하면 테스트 데이터 기반으로 다시 CountVectorizer가 fit()을 수행하고 transform()하기\n",
        "# 때문에 학습 시 사용된 피처 개수와 예측 시 사용할 피처 개수가 달라진다."
      ],
      "metadata": {
        "id": "CvzqDu0Jyy7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Count Vectorization으로 피처 벡터화 변환 수행.\n",
        "cnt_vect = CountVectorizer()\n",
        "cnt_vect.fit(X_train)\n",
        "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
        "\n",
        "# 학습 데이터로 fit()된 CountVectorizer를 이용해 텍스트 데이터를 피처 벡터화 수행.\n",
        "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
        "\n",
        "print('학습 데이터 Text의 CountVectorizer Shape:', X_train_cnt_vect.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peY4HZoB0PxS",
        "outputId": "5980c80e-92f6-4e85-9a30-7d2f6f14667a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 Text의 CountVectorizer Shape: (11314, 101631)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# LogisticRegression을 이용해 학습/예측/평가 수행.\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train_cnt_vect, y_train)\n",
        "pred = lr_clf.predict(X_test_cnt_vect)\n",
        "print('CountVectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1nOGsKi1EPL",
        "outputId": "99544a13-4fda-4bd8-a334-4f14266e6b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorized Logistic Regression의 예측 정확도는 0.604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF 벡터화를 적용해 학습 데이터 세트와 테스트 데이터 세트 변환.\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
        "\n",
        "# LogistcRegression을 이용해 학습/예측/평가 수행.\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
        "pred = lr_clf.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gujLs-Hy2Vod",
        "outputId": "b290ae76-68d0-4c1d-b6bb-a571bb183fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Logistic Regression의 예측 정확도는 0.674456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트분석에서 머신러닝 모델의 성능을 향상시키는 중요한 2가지 방법은 최적의 ML 알고리즘을 선택하는 것과 최상의 피처 전처리를 수행하는 것이다.\n",
        "# 텍스트 정규화나 Count/TF-IDF 기반 피처 벡터화를 어떻게 효과적으로 적용했는지가 텍스트 기반의 머신러닝 성능에 큰 영향을 미칠 수 있다.\n",
        "# stop words 필터링을 추가하고 ngram을 기본(1,1)에서 (1,2)로 변경해 피처 벡터화 적용.\n",
        "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
        "\n",
        "lr_clf = LogisticRegression(solver='liblinear')\n",
        "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
        "pred = lr_clf.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLPSa1ji3eXa",
        "outputId": "20b101b4-67ca-4844-df84-1d90a4fadbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV를 이용해 로지스틱 회귀의 하이퍼파라미터 최적화 수행\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 최적 C 값 도출 튜닝 수행. CV는 3 폴드 세트로 설정.\n",
        "params = {'C': [0.01, 0.1, 1, 5, 10]}\n",
        "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_cv_lr.fit(X_train_tfidf_vect, y_train)\n",
        "print('Logistic Regression best C parameter :', grid_cv_lr.best_params_)\n",
        "\n",
        "# 최적 C값으로 학습된 grid_cv로 예측 정확도 평가.\n",
        "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Vectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AqJkcti9Rge",
        "outputId": "862b19b1-eac2-424c-adce-694a75020bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "Logistic Regression best C parameter : {'C': 10}\n",
            "TF-IDF Vectorized Logistic Regression의 예측 정확도는 0.704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4-3. 사이킷런 파이프라인 사용 및 GridSearchCV와의 결합"
      ],
      "metadata": {
        "id": "GepzMwoYCA-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런의 pipeline 클래스를 이용하면 피처 벡터화와 ML 알고리즘 학습/예측을 위한 코드 작성을 한 번에 진행할 수 있다.\n",
        "# 이 코드는 TfidfVectorizer 객체를 tfidf_vect라는 객체 변수명으로, logisticRegression 객체를 lr_clf라는 객체 변수명으로\n",
        "# 생성한 뒤 이 두 개의 객체를 파이프라인으로 연결하는 Pipeline 객체 pipeline을 생성한다는 의미이다. 또한 다음 코드를 보면\n",
        "# 기존 TfIdfVectorizer의 학습 데이터와 테스트 데이터에 대한 fit()과 transform()수행을 통한 피처 벡터화와 LogisticRegressor의\n",
        "# fit() 과 predict() 수행을 통한 머신러닝 모델의 학습과 예측이 Pipeline의 fit()과 predict()로 통일돼 수행됨을 알 수 있다.\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipeline = Pipeline([('tfidf_vect', TfidfVectorizer(stop_words='english')), ('lr_clf', LogisticRegression(random_state=156))])\n",
        "\n",
        "# TfidfVectorizer 객체를 tfidf_vect로, LogisticRegression 객체를 lr_clf로 생성하는 pipline 생성\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)),\n",
        "    ('lr_clf', LogisticRegression(C=10))\n",
        "])\n",
        "# 별도의 TfidfVectorizer 객체의 fit(), transform()과 LogisticRegression의 fit() 과 predict()가 필요없음\n",
        "# pipline이 fit과 predict만으로 한꺼번에 피처 벡터화와 ML학습/예측이 가능.\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "pred = pipeline.predict(X_test)\n",
        "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ_xHjzEB_CN",
        "outputId": "c4d14abe-987c-4e1a-eea2-92c6802697bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline을 통한 Logistic Regression의 예측 정확도는 0.701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV에 pipeline을 입력하면서 TfidfVectorizer의 파라미터와\n",
        "# LogisticRegression의 하이퍼파라미터를 함께 최적화한다.\n",
        "# 다만 key값을 살펴보면 'tfidf_vect__ngram_range'와 같이 하이퍼 파라미터명이 객체 변수명과 결합돼 제공된다.\n",
        "# pipeline을 gridsearchCV에 인자로 입력되면 GridSearchCV는 Pipeline을 구성하는 피처 벡터화 객체의 파라미터와\n",
        "# Estimator 객체의 하이퍼 파라미터를 각각 구별할 수 있어야하는데, 이때 개별 객체 명과 파라미터명/하이퍼 파라미터명을 결합해\n",
        "# Key 값으로 할당하는 것이다.\n",
        "\n",
        "# 로지스틱 회귀외에 서포트 벡터머신과 나이브 베이즈알고리즘도 희소행렬기반의 텍스트 분류에 자주 사용되는 머신러닝 알고리즘이다.\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "\n",
        "# Pipeline에 기술된 각각의 객체 변수에 언더바(_)2개를 연달아 붙여 GridSearchCV에 사용될\n",
        "# 파라미터/하이퍼 파라미터 이름과 값을 설정. .\n",
        "params = { 'tfidf_vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
        "           'tfidf_vect__max_df': [100, 300, 700],\n",
        "           'lr_clf__C': [1,5,10]\n",
        "}\n",
        "\n",
        "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
        "grid_cv_pipe = GridSearchCV(pipeline, param_grid=params, cv=3 , scoring='accuracy',verbose=1)\n",
        "grid_cv_pipe.fit(X_train , y_train)\n",
        "print(grid_cv_pipe.best_params_ , grid_cv_pipe.best_score_)\n",
        "\n",
        "pred = grid_cv_pipe.predict(X_test)\n",
        "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLo1RAwGF2hx",
        "outputId": "2ce52b3f-2eb8-4c13-ecae-bf0addc108b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "{'lr_clf__C': 10, 'tfidf_vect__max_df': 700, 'tfidf_vect__ngram_range': (1, 2)} 0.7550828826229531\n",
            "Pipeline을 통한 Logistic Regression 의 예측 정확도는 0.702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.감정분석"
      ],
      "metadata": {
        "id": "yy6mvb6qQGWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정분석에는 두 가지 방식이 있다.\n",
        "# 1. 지도학습은 학습 데이터와 타깃 레이블 값을 기반으로 감정 분석 학습을 수행한 뒤 이를 기반으로 다른 데이터의 감성 분석을\n",
        "# 예측하는 방법으로 일반적인 텍스트 기반의 분류와 거의 동일하다.\n",
        "# 2. 비지도학습은 'Lexicon'이라는 일종의 감성 어휘 사전을 이용한다. Lexicon은 감성 분석을 위한 용어와 문맥에 대한 다양한 정보를 가지고 있으며,\n",
        "# 이를 이용해 문서의 긍정적, 부정적 감성 여부를 판단한다."
      ],
      "metadata": {
        "id": "Alf-K1zyPisG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5-1. 지도학습 기반 감정 분석실습 - IMDB 영화평"
      ],
      "metadata": {
        "id": "8X1yDA-uQxLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "review_df = pd.read_csv('./labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
        "review_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "8vumSIMdQw23",
        "outputId": "1fd7826e-58a8-4458-e685-c38fb3c3c995"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dc3a9d8-dfa6-4b30-8c55-eeaf689d1227\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dc3a9d8-dfa6-4b30-8c55-eeaf689d1227')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9dc3a9d8-dfa6-4b30-8c55-eeaf689d1227 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9dc3a9d8-dfa6-4b30-8c55-eeaf689d1227');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2b5e303f-a628-4acd-afc0-0762fd1949ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b5e303f-a628-4acd-afc0-0762fd1949ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2b5e303f-a628-4acd-afc0-0762fd1949ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "review_df",
              "summary": "{\n  \"name\": \"review_df\",\n  \"rows\": 4609,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4609,\n        \"samples\": [\n          \"\\\"7333_10\\\"\",\n          \"\\\"7423_4\\\"\",\n          \"\\\"6998_4\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4605,\n        \"samples\": [\n          \"\\\"What the hell is in your minds ? This film sucks ! Each minute I was getting more and more bored. I strove to watch the end because I hope something at least would at last happen ! But instead of that, I got amazed how dull the end was treated... What is this story about this bloody \\\\\\\"bogeyman\\\\\\\" ? How comes he doesn't die ? He is a bloody human being for God's sake ! A mere boy that killed his silly sister 15 years ago. Then what ? His stay on a psychiatric hospital made him immortal ? This film a fascinatingly stupid... It's a must of silliness. I'm gonna resell it right now to some silly guy who will understand this silly film.\\\"\",\n          \"\\\"I was about thirteen when this movie came out on television. It is far superior in action than most movies since. Martin Sheen is excellent, and though Nick Nolte has a small part, he too provides excellent support. Vic Morrow as the villain is superb.<br /><br />When Sheen \\\\\\\"tests the water\\\\\\\" in his '34 Ford (COOL) along the mountainous highway it is spectacular!<br /><br />The ending is grand.<br /><br />I'm disappointed in the low vote this received. I figure the younger generations have more interest in much of the junk that is coming out these days.<br /><br />Good taste eludes the masses!\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(review_df['review'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khJh1i9kSEw0",
        "outputId": "f6d46c9d-c727-4998-9e2a-6bdf25a66e7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# <br> html 태그는 replace 함수로 공백으로 변환\n",
        "review_df['review'] = review_df['review'].str.replace('<br />',' ')\n",
        "\n",
        "# 파이썬의 정규 표현식 모듈인 re를 이용해 영어 문자열이 아닌 문자는 모두 공백으로 변환\n",
        "review_df['review'] = review_df['review'].apply(lambda x : re.sub(\"[^a-zA-Z]\", \" \", x))"
      ],
      "metadata": {
        "id": "ROI3G0IxStCf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "class_df = review_df['sentiment']\n",
        "feature_df = review_df.drop(['id','sentiment'], axis=1, inplace=False)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, class_df, test_size=0.3, random_state=156)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqfObxoaGAlr",
        "outputId": "ca98414a-077b-4804-9e2b-93ab15f311e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3226, 1), (1383, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count 벡터화\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# 스톱 워드는 English, ngram은 (1,2)로 설정해 CountVectorization 수행.\n",
        "# LogisticRegression의 C는 10으로 설정.\n",
        "pipeline = Pipeline([\n",
        "    ('cnt_vect', CountVectorizer(stop_words='english', ngram_range = (1,2))),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear', C=10))\n",
        "])\n",
        "\n",
        "# Piplline 객체를 이용해 fit(), predict()로 학습/예측 수행. predict_proba()는 roc_auc 때문에 수행.\n",
        "pipeline.fit(X_train['review'], y_train)\n",
        "pred = pipeline.predict(X_test['review'])\n",
        "pred_probs = pipeline.predict_proba(X_test['review'])[:,1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test, pred), roc_auc_score(y_test, pred_probs)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6FH893DpTzl",
        "outputId": "bc1f5f10-ee45-4e8b-8395-35a219be613e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도는 0.8590, ROC-AUC는 0.9254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "# 스톱 워드는 english, filtering, ngram은 (1,2)로 설정해 TF-IDF 벡터화 수행.\n",
        "# logisticRegression의 C는 10으로 설정\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range = (1,2))),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear', C=10))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train['review'], y_train)\n",
        "pred = pipeline.predict(X_test['review'])\n",
        "pred_probs = pipeline.predict_proba(X_test['review'])[:,1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test, pred), roc_auc_score(y_test, pred_probs)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocZ0xnXAqwx0",
        "outputId": "8edf64c1-b9e3-4d6d-be0c-a9cfe26d7023"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도는 0.8583, ROC-AUC는 0.9365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5-2. 비지도학습 기반 감성 분석 소개"
      ],
      "metadata": {
        "id": "rkS48gcBroI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 많은 감성 분석용 데이터는 이러한 결정된 레이블 값을 가지고 있지 않다. 이러한 경우는 Lexicon은 유용하게 사용될 수 있다.\n",
        "# NLTK 패키지의 WordNet은 방대한 영어 어휘 사전이다. 그러나 단순한 어휘사전이 아닌 시맨틱 분석을 제공하는 어휘사전이다.\n",
        "# 시맨틱은 문맥상 의미를 뜻한다.\n",
        "# WordNet은 다양한 상황에서 같은 어휘라도 다르게 사용되는 어휘의 시맨틱 정보를 제공하며, 이를 위해 각각의 품사로 구성된 개별 단어를\n",
        "# Synset이라는 개념을 이용해 표현한다. Synset은 단순한 하나의 단어가 아니라 그 단어가 가지는 문맥, 시맨틱 정보를 제공하는 WordNet의 핵심이다."
      ],
      "metadata": {
        "id": "vi-UCseyrr79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5-2-1. SentiWordNet을 이용한 감성분석"
      ],
      "metadata": {
        "id": "MJgzFtsltcrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGsyB3barbSP",
        "outputId": "ac7a22d9-4723-4b15-83c1-d7ed3747b204"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package mock_corpus to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mock_corpus.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "term = 'present'\n",
        "\n",
        "# 'present'라는 단어로 wordnet의 synsets 생성.\n",
        "\n",
        "synsets = wn.synsets(term)\n",
        "print('synsets() 반환 type :', type(synsets))\n",
        "print('synsets() 반환 값 갯수:', len(synsets))\n",
        "print('synsets() 반환 값 :', synsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kySQ00Zntx4U",
        "outputId": "724d280b-2d34-4210-ae1f-31f71eb7f8b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "synsets() 반환 type : <class 'list'>\n",
            "synsets() 반환 값 갯수: 18\n",
            "synsets() 반환 값 : [Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for synset in synsets :\n",
        "    print('##### Synset name : ', synset.name(), '#####')\n",
        "    print('POS :', synset.lexname())\n",
        "    print('Definition :', synset.definition())\n",
        "    print('Lemmas :', synset.lemma_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv8bpP0HuIW1",
        "outputId": "ae914fda-bba6-44a8-aebf-ba4f59f62bba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Synset name :  present.n.01 #####\n",
            "POS : noun.time\n",
            "Definition : the period of time that is happening now; any continuous stretch of time including the moment of speech\n",
            "Lemmas : ['present', 'nowadays']\n",
            "##### Synset name :  present.n.02 #####\n",
            "POS : noun.possession\n",
            "Definition : something presented as a gift\n",
            "Lemmas : ['present']\n",
            "##### Synset name :  present.n.03 #####\n",
            "POS : noun.communication\n",
            "Definition : a verb tense that expresses actions or states at the time of speaking\n",
            "Lemmas : ['present', 'present_tense']\n",
            "##### Synset name :  show.v.01 #####\n",
            "POS : verb.perception\n",
            "Definition : give an exhibition of to an interested audience\n",
            "Lemmas : ['show', 'demo', 'exhibit', 'present', 'demonstrate']\n",
            "##### Synset name :  present.v.02 #####\n",
            "POS : verb.communication\n",
            "Definition : bring forward and present to the mind\n",
            "Lemmas : ['present', 'represent', 'lay_out']\n",
            "##### Synset name :  stage.v.01 #####\n",
            "POS : verb.creation\n",
            "Definition : perform (a play), especially on a stage\n",
            "Lemmas : ['stage', 'present', 'represent']\n",
            "##### Synset name :  present.v.04 #####\n",
            "POS : verb.possession\n",
            "Definition : hand over formally\n",
            "Lemmas : ['present', 'submit']\n",
            "##### Synset name :  present.v.05 #####\n",
            "POS : verb.stative\n",
            "Definition : introduce\n",
            "Lemmas : ['present', 'pose']\n",
            "##### Synset name :  award.v.01 #####\n",
            "POS : verb.possession\n",
            "Definition : give, especially as an honor or reward\n",
            "Lemmas : ['award', 'present']\n",
            "##### Synset name :  give.v.08 #####\n",
            "POS : verb.possession\n",
            "Definition : give as a present; make a gift of\n",
            "Lemmas : ['give', 'gift', 'present']\n",
            "##### Synset name :  deliver.v.01 #####\n",
            "POS : verb.communication\n",
            "Definition : deliver (a speech, oration, or idea)\n",
            "Lemmas : ['deliver', 'present']\n",
            "##### Synset name :  introduce.v.01 #####\n",
            "POS : verb.communication\n",
            "Definition : cause to come to know personally\n",
            "Lemmas : ['introduce', 'present', 'acquaint']\n",
            "##### Synset name :  portray.v.04 #####\n",
            "POS : verb.creation\n",
            "Definition : represent abstractly, for example in a painting, drawing, or sculpture\n",
            "Lemmas : ['portray', 'present']\n",
            "##### Synset name :  confront.v.03 #####\n",
            "POS : verb.communication\n",
            "Definition : present somebody with something, usually to accuse or criticize\n",
            "Lemmas : ['confront', 'face', 'present']\n",
            "##### Synset name :  present.v.12 #####\n",
            "POS : verb.communication\n",
            "Definition : formally present a debutante, a representative of a country, etc.\n",
            "Lemmas : ['present']\n",
            "##### Synset name :  salute.v.06 #####\n",
            "POS : verb.communication\n",
            "Definition : recognize with a gesture prescribed by a military regulation; assume a prescribed position\n",
            "Lemmas : ['salute', 'present']\n",
            "##### Synset name :  present.a.01 #####\n",
            "POS : adj.all\n",
            "Definition : temporal sense; intermediate between past and future; now existing or happening or in consideration\n",
            "Lemmas : ['present']\n",
            "##### Synset name :  present.a.02 #####\n",
            "POS : adj.all\n",
            "Definition : being or existing in a specified place\n",
            "Lemmas : ['present']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# synset 객체를 단어별로 생성한다.\n",
        "tree = wn.synset('tree.n.01')\n",
        "lion = wn.synset('lion.n.01')\n",
        "tiger = wn.synset('tiger.n.02')\n",
        "cat = wn.synset('cat.n.01')\n",
        "dog = wn.synset('dog.n.01')\n",
        "\n",
        "entities = [tree, lion, tiger, cat, dog]\n",
        "similarities = []\n",
        "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
        "\n",
        "# 단어별 synset 들을 iteration 하면서 다른 단어들의 synset과 유사도를 측정\n",
        "for entity in entities:\n",
        "    similarity = [round(entity.path_similarity(compared_entity), 2) for compared_entity in entities]\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# 개별 단어별 synset과 다른 단어의 synset과의 유사도를 DataFrame 형태로 저장한다.\n",
        "similarity_df = pd.DataFrame(similarities, columns = entity_names, index=entity_names)\n",
        "similarity_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ALHYVJMnuusX",
        "outputId": "c7dc9080-1b9e-4166-a4fb-044016f567f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       tree  lion  tiger   cat   dog\n",
              "tree   1.00  0.07   0.07  0.08  0.12\n",
              "lion   0.07  1.00   0.33  0.25  0.17\n",
              "tiger  0.07  0.33   1.00  0.25  0.17\n",
              "cat    0.08  0.25   0.25  1.00  0.20\n",
              "dog    0.12  0.17   0.17  0.20  1.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c366b8f-67a9-4246-928f-f66ee95def4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tree</th>\n",
              "      <th>lion</th>\n",
              "      <th>tiger</th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tree</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lion</th>\n",
              "      <td>0.07</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tiger</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat</th>\n",
              "      <td>0.08</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c366b8f-67a9-4246-928f-f66ee95def4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c366b8f-67a9-4246-928f-f66ee95def4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c366b8f-67a9-4246-928f-f66ee95def4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-035e1a48-f6bc-4d5d-8a41-6e8e64e5b4bb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-035e1a48-f6bc-4d5d-8a41-6e8e64e5b4bb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-035e1a48-f6bc-4d5d-8a41-6e8e64e5b4bb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5e3b97e8-c621-4eda-9baf-9ee5db10ab14\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('similarity_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5e3b97e8-c621-4eda-9baf-9ee5db10ab14 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('similarity_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "similarity_df",
              "summary": "{\n  \"name\": \"similarity_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tree\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40971941618624813,\n        \"min\": 0.07,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.07,\n          0.12,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3683476618630828,\n        \"min\": 0.07,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          0.17,\n          0.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tiger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3683476618630828,\n        \"min\": 0.07,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.33,\n          0.17,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36664696916789047,\n        \"min\": 0.08,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.25,\n          0.2,\n          0.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dog\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3745263675630862,\n        \"min\": 0.12,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.17,\n          1.0,\n          0.12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "senti_synsets = list(swn.senti_synsets('slow'))\n",
        "print('senti_synsets() 반환 type :', type(senti_synsets))\n",
        "print('senti_synsets() 반환 값 갯수:', len(senti_synsets))\n",
        "print('senti_synsets() 반환 값 :', senti_synsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm8y3QvYw9PA",
        "outputId": "7b9546b0-97e2-485b-824a-0cb06e69b0db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "senti_synsets() 반환 type : <class 'list'>\n",
            "senti_synsets() 반환 값 갯수: 11\n",
            "senti_synsets() 반환 값 : [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentisynset 객체는 단어의 감성을 나타내는 감성 지수와 객관성을 나타내는 객관성 지수를 가지고 있다.\n",
        "# 감성지수는 다시 긍정 감성 지수와 부정 감성 지수로 나뉜다.\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "father = swn.senti_synset('father.n.01')\n",
        "\n",
        "print('father 긍정감성 지수: ', father.pos_score())\n",
        "print('father 부정감성 지수: ', father.neg_score())\n",
        "print('father 객관성 지수: ', father.obj_score())\n",
        "print('\\n')\n",
        "\n",
        "fabulous = swn.senti_synset('fabulous.a.01')\n",
        "print('fabulous 긍정감성 지수:', fabulous.pos_score())\n",
        "print('fabulous 부정감성 지수:', fabulous.neg_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOdGWWRU54DP",
        "outputId": "c8196310-01de-4992-a6ac-9303aa2a6a25"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "father 긍정감성 지수:  0.0\n",
            "father 부정감성 지수:  0.0\n",
            "father 객관성 지수:  1.0\n",
            "\n",
            "\n",
            "fabulous 긍정감성 지수: 0.875\n",
            "fabulous 부정감성 지수: 0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SentiWordNet을 이용한 영화 감상평 감성 분석\n",
        "# 1. 문서를 문장 단위로 분해\n",
        "# 2. 다시 문장을 단어 단위로 토큰화하고 품사 태깅\n",
        "# 3. 품사 태깅된 단어 기반으로 synset 객체와 senti_synset 객체를 생성\n",
        "# 4. senti_synset 객체에서 긍정/부정 감성지수를 구하고 이를 합산해 특정 임계치 값 이상일 때 긍정 감성으로, 그렇지 않을 때는\n",
        "#    부정 감성으로 결정"
      ],
      "metadata": {
        "id": "jrT-sFrR7ZWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "# 간단한 NTLK PennTreebank Tag를 기반으로 WordNet 기반의 품사 Tag로 변환\n",
        "def penn_to_wn(tag):\n",
        "    if tag.startswith('J'):\n",
        "       return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "       return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "       return wn.ADV\n",
        "    elif tag.startswith('V'):\n",
        "       return wn.VERB"
      ],
      "metadata": {
        "id": "tWvzCREa83Ge"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 -> 단어 토큰 -> 품사 태깅\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "def swn_polarity(text):\n",
        "    # 감성 지수 초기화\n",
        "    sentiment = 0.0\n",
        "    tokens_count = 0\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    raw_sentences = sent_tokenize(text)\n",
        "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산\n",
        "    for raw_sentence in raw_sentences:\n",
        "        # NTLK 기반의 품사 태깅 문장 추출\n",
        "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
        "        for word, tag in tagged_sentence:\n",
        "            # WordNet 기반 품사 태깅과 어근 추출\n",
        "            wn_tag = penn_to_wn(tag)\n",
        "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
        "                continue\n",
        "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "            if not lemma:\n",
        "                continue\n",
        "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성.\n",
        "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
        "            if not synsets:\n",
        "                continue\n",
        "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
        "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산.\n",
        "            synset = synsets[0]\n",
        "            swn_synset = swn.senti_synset(synset.name())\n",
        "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n",
        "            tokens_count += 1\n",
        "\n",
        "        if not tokens_count:\n",
        "            return 0\n",
        "\n",
        "        # 총 score가 0 이상일 경우 긍정 (positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
        "        if sentiment >= 0:\n",
        "            return 1\n",
        "\n",
        "        return 0"
      ],
      "metadata": {
        "id": "-bdCgo6s9jIE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# swn_polarity(text) 함수를 IMDB 감사평의 개별 문서에 적용해 긍정 및 부정 감성을 예측\n",
        "# review_df의 새로운 칼럼으로 'preds'를 추가해 이 칼럼에 swn_polarity(text)로 반환된 감성 평가를 담는다.\n",
        "# 그리고 실제 감성 평가인 'sentiment' 칼럼과 swn_polarity(text)로 반환된 결과를 평가한다.\n",
        "\n",
        "review_df['preds'] = review_df['review'].apply( lambda x : swn_polarity(x) )\n",
        "y_target = review_df['sentiment'].values\n",
        "preds = review_df['preds'].values"
      ],
      "metadata": {
        "id": "P6NEanYzA0pJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "\n",
        "print(confusion_matrix( y_target, preds))\n",
        "print(\"정확도:\", accuracy_score(y_target , preds))\n",
        "print(\"정밀도:\", precision_score(y_target , preds))\n",
        "print(\"재현율:\", recall_score(y_target, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVCdhw2YA-sb",
        "outputId": "1d4976a9-e67a-4af8-e6f9-8f25fbe59469"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1353  937]\n",
            " [ 665 1654]]\n",
            "정확도: 0.6524191798654806\n",
            "정밀도: 0.6383635661906599\n",
            "재현율: 0.7132384648555412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5-2-2. VADER를 이용한 감성분석"
      ],
      "metadata": {
        "id": "EvfGzHbBG3pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VADER는 소셜 미디어의 감성 분석 용도로 만들어진 룰 기반의 Lexicon이다."
      ],
      "metadata": {
        "id": "yHGQvdnjG77L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "senti_analyzer = SentimentIntensityAnalyzer()\n",
        "senti_scores = senti_analyzer.polarity_scores(review_df['review'][0])\n",
        "print(senti_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK7nJG8WHEph",
        "outputId": "c9baa709-dcbc-4938-c701-43e2060f8149"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.13, 'neu': 0.743, 'pos': 0.127, 'compound': -0.7943}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vader_polarity(review,threshold=0.1):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(review)\n",
        "\n",
        "    # compound 값에 기반하여 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환\n",
        "    agg_score = scores['compound']\n",
        "    final_sentiment = 1 if agg_score >= threshold else 0\n",
        "    return final_sentiment\n",
        "\n",
        "# apply lambda 식을 이용하여 레코드별로 vader_polarity( )를 수행하고 결과를 'vader_preds'에 저장\n",
        "review_df['vader_preds'] = review_df['review'].apply( lambda x : vader_polarity(x, 0.1) )\n",
        "y_target = review_df['sentiment'].values\n",
        "vader_preds = review_df['vader_preds'].values"
      ],
      "metadata": {
        "id": "2TbpwO1LHL9C"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('#### VADER 예측 성능 평가 ####')\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "\n",
        "print(confusion_matrix( y_target, vader_preds))\n",
        "print(\"정확도:\", accuracy_score(y_target , vader_preds))\n",
        "print(\"정밀도:\", precision_score(y_target , vader_preds))\n",
        "print(\"재현율:\", recall_score(y_target, vader_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdK_0IQNHNxZ",
        "outputId": "d6bc660c-200c-46e3-f9e2-c6b09976ae3e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### VADER 예측 성능 평가 ####\n",
            "[[1232 1058]\n",
            " [ 318 2001]]\n",
            "정확도: 0.7014536775873291\n",
            "정밀도: 0.6541353383458647\n",
            "재현율: 0.8628719275549805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.토픽 모델링 - 20 뉴스그룹"
      ],
      "metadata": {
        "id": "WXHp0REBKzdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 토픽 모델링이란 문서 집합에 숨어 있는 주제를 찾아내는 것이다.\n",
        "# 많은 양의 문서가 있을 때 사람이 이 문서를 다 읽고 핵심 주제를 찾는 것은 매우 많은 시간이 소모된다.\n",
        "# 머신러닝 기반의 토픽 모델링에 자주 사용되는 기법은 LSA, LDA가 있다. 이번 절에는 LDA를 사용하고 차원축소의 LDA와 다른 용어이다."
      ],
      "metadata": {
        "id": "28SasQ2bK4IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 등 8개 주제를 추출.\n",
        "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
        "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
        "\n",
        "# 위에서 cats 변수로 기재된 category만 추출. featch_20newsgroups( )의 categories에 cats 입력\n",
        "news_df = fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'),\n",
        "                            categories=cats, random_state=0)\n",
        "\n",
        "#LDA 는 Count기반의 Vectorizer만 적용합니다.\n",
        "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1,2))\n",
        "feat_vect = count_vect.fit_transform(news_df.data)\n",
        "print('CountVectorizer Shape:', feat_vect.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQpo9B8HM4md",
        "outputId": "e8645108-33e8-494c-abaa-4a28db4f82af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer Shape: (7862, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQiiCvNSN6yN",
        "outputId": "bfa77b3f-1a0c-4668-9d68-553ab463ceee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['00', '000', '01', '02', '03', '04', '05', '10', '100', '11', '12',\n",
              "       '128', '13', '14', '15', '16', '17', '18', '19', '1990', '1991',\n",
              "       '1992', '1993', '20', '200', '21', '22', '23', '24', '24 bit',\n",
              "       '25', '256', '26', '27', '28', '29', '30', '300', '31', '32', '35',\n",
              "       '3d', '40', '44', '50', '500', '60', '80', '800', '90', '91', '92',\n",
              "       '93', 'ability', 'able', 'ac', 'accept', 'accepted', 'access',\n",
              "       'according', 'act', 'action', 'actions', 'acts', 'actually', 'add',\n",
              "       'added', 'addition', 'address', 'adl', 'advance', 'age', 'ago',\n",
              "       'agree', 'aids', 'al', 'allow', 'american', 'amiga', 'analysis',\n",
              "       'anonymous', 'anonymous ftp', 'answer', 'answers', 'anti',\n",
              "       'anybody', 'apartment', 'apparently', 'appear', 'appears',\n",
              "       'application', 'applications', 'apply', 'appreciate',\n",
              "       'appreciated', 'approach', 'appropriate', 'april', 'arab', 'arabs',\n",
              "       'archive', 'area', 'areas', 'aren', 'argic', 'argument', 'armenia',\n",
              "       'armenian', 'armenians', 'army', 'art', 'article', 'articles',\n",
              "       'ask', 'asked', 'assume', 'attack', 'attempt', 'author',\n",
              "       'available', 'average', 'avoid', 'away', 'azerbaijan',\n",
              "       'azerbaijani', 'bad', 'ball', 'base', 'baseball', 'based', 'basic',\n",
              "       'basis', 'battery', 'belief', 'believe', 'best', 'better', 'bible',\n",
              "       'big', 'bike', 'bit', 'bits', 'black', 'blood', 'blue', 'board',\n",
              "       'body', 'book', 'books', 'born', 'box', 'break', 'bring',\n",
              "       'british', 'brought', 'build', 'building', 'built', 'bus', 'buy',\n",
              "       'ca', 'california', 'called', 'came', 'cancer', 'car', 'card',\n",
              "       'care', 'case', 'cases', 'catholic', 'cause', 'center', 'century',\n",
              "       'certain', 'certainly', 'chance', 'change', 'changed', 'changes',\n",
              "       'char', 'check', 'child', 'children', 'choice', 'christ',\n",
              "       'christian', 'christianity', 'christians', 'church', 'circuit',\n",
              "       'city', 'claim', 'claims', 'class', 'clear', 'clearly', 'client',\n",
              "       'clients', 'clinical', 'close', 'code', 'color', 'colors', 'com',\n",
              "       'come', 'comes', 'coming', 'command', 'comments', 'commercial',\n",
              "       'common', 'community', 'comp', 'company', 'complete', 'completely',\n",
              "       'computer', 'condition', 'conference', 'consider', 'considered',\n",
              "       'contact', 'contains', 'context', 'continue', 'contrib', 'control',\n",
              "       'conversion', 'convert', 'copy', 'correct', 'cost', 'couldn',\n",
              "       'count', 'countries', 'country', 'couple', 'course', 'create',\n",
              "       'created', 'cs', 'culture', 'current', 'currently', 'cut', 'data',\n",
              "       'date', 'david', 'day', 'days', 'dead', 'deal', 'death', 'dec',\n",
              "       'default', 'define', 'defined', 'definition', 'deleted',\n",
              "       'department', 'described', 'description', 'design', 'designed',\n",
              "       'details', 'developed', 'development', 'did', 'didn', 'die',\n",
              "       'died', 'diet', 'difference', 'different', 'difficult', 'digital',\n",
              "       'directly', 'directory', 'discussion', 'disease', 'disk',\n",
              "       'display', 'distribution', 'doctor', 'dod', 'does', 'does know',\n",
              "       'doesn', 'dog', 'doing', 'don', 'don know', 'don think', 'door',\n",
              "       'dos', 'dos dos', 'double', 'doubt', 'dr', 'draw', 'drive',\n",
              "       'driver', 'drug', 'earlier', 'early', 'earth', 'easily', 'east',\n",
              "       'easy', 'echo', 'ed', 'edu', 'effect', 'effects', 'email', 'end',\n",
              "       'entire', 'entries', 'entry', 'environment', 'error', 'especially',\n",
              "       'europe', 'event', 'events', 'evidence', 'exactly', 'example',\n",
              "       'exist', 'existence', 'expect', 'experience', 'export', 'extra',\n",
              "       'eye', 'eyes', 'face', 'fact', 'fairly', 'faith', 'false',\n",
              "       'family', 'faq', 'far', 'fast', 'faster', 'father', 'fax',\n",
              "       'features', 'feel', 'field', 'figure', 'file', 'files', 'final',\n",
              "       'finally', 'fine', 'follow', 'following', 'font', 'fonts', 'food',\n",
              "       'force', 'form', 'format', 'formats', 'frame', 'free', 'friend',\n",
              "       'ftp', 'function', 'functions', 'future', 'game', 'games', 'gave',\n",
              "       'general', 'generally', 'genocide', 'gets', 'getting', 'gif',\n",
              "       'given', 'gives', 'giving', 'god', 'goes', 'going', 'gone', 'good',\n",
              "       'got', 'gov', 'government', 'graphics', 'great', 'greatly',\n",
              "       'greece', 'greek', 'green', 'ground', 'group', 'groups', 'guess',\n",
              "       'guy', 'guys', 'half', 'hand', 'handle', 'hands', 'happen',\n",
              "       'happened', 'happens', 'happy', 'hard', 'hardware', 'hate',\n",
              "       'haven', 'having', 'head', 'health', 'hear', 'heard', 'heart',\n",
              "       'heaven', 'held', 'hell', 'help', 'hi', 'high', 'higher',\n",
              "       'history', 'hit', 'hiv', 'hold', 'holy', 'home', 'homosexual',\n",
              "       'homosexuality', 'hope', 'hospital', 'host', 'hot', 'hours',\n",
              "       'house', 'hp', 'human', 'ibm', 'idea', 'ideas', 'ii', 'image',\n",
              "       'images', 'imagine', 'important', 'include', 'included',\n",
              "       'includes', 'including', 'individual', 'infection', 'info',\n",
              "       'information', 'input', 'inside', 'instead', 'int', 'interested',\n",
              "       'interesting', 'interface', 'international', 'internet',\n",
              "       'involved', 'isn', 'israel', 'israeli', 'issue', 'issues',\n",
              "       'istanbul', 'jesus', 'jewish', 'jews', 'job', 'john', 'jpeg',\n",
              "       'just', 'key', 'keyboard', 'kill', 'killed', 'kind', 'knew',\n",
              "       'know', 'knowledge', 'known', 'knows', 'kuwait', 'land',\n",
              "       'language', 'large', 'later', 'latest', 'law', 'lcs', 'lcs mit',\n",
              "       'lead', 'league', 'learn', 'leave', 'led', 'left', 'let', 'level',\n",
              "       'lib', 'library', 'life', 'light', 'like', 'likely', 'limited',\n",
              "       'line', 'lines', 'list', 'little', 'live', 'lived', 'lives',\n",
              "       'living', 'll', 'local', 'long', 'longer', 'look', 'looked',\n",
              "       'looking', 'looks', 'lord', 'lost', 'lot', 'lots', 'love', 'low',\n",
              "       'mac', 'machine', 'machines', 'mail', 'mailing', 'main', 'major',\n",
              "       'make', 'makes', 'making', 'man', 'manager', 'manual', 'mark',\n",
              "       'marriage', 'mary', 'matter', 'maybe', 'mean', 'meaning', 'means',\n",
              "       'medical', 'medicine', 'member', 'members', 'memory', 'men',\n",
              "       'mentioned', 'message', 'method', 'michael', 'middle', 'mike',\n",
              "       'military', 'million', 'mind', 'mit', 'mit edu', 'mode', 'model',\n",
              "       'modern', 'money', 'months', 'mother', 'motif', 'mouse',\n",
              "       'movement', 'mr', 'ms', 'msg', 'multiple', 'muslim', 'muslims',\n",
              "       'national', 'natural', 'nature', 'nazi', 'near', 'necessary',\n",
              "       'need', 'needed', 'needs', 'net', 'network', 'new', 'new york',\n",
              "       'news', 'newsgroup', 'nice', 'night', 'non', 'normal', 'note',\n",
              "       'null', 'number', 'numbers', 'object', 'objects', 'obviously',\n",
              "       'office', 'official', 'oh', 'ok', 'old', 'ones', 'open',\n",
              "       'openwindows', 'opinion', 'order', 'organization', 'original',\n",
              "       'os', 'ottoman', 'output', 'outside', 'package', 'page', 'pages',\n",
              "       'pain', 'palestinian', 'palestinians', 'paper', 'parents',\n",
              "       'particular', 'parts', 'party', 'pass', 'past', 'path', 'patient',\n",
              "       'patients', 'paul', 'pc', 'peace', 'people', 'percent',\n",
              "       'performance', 'person', 'personal', 'phone', 'picture', 'pixel',\n",
              "       'place', 'places', 'play', 'player', 'players', 'plus', 'point',\n",
              "       'points', 'police', 'policy', 'political', 'population',\n",
              "       'position', 'possible', 'possibly', 'post', 'posted', 'posting',\n",
              "       'postscript', 'power', 'practice', 'present', 'press', 'pretty',\n",
              "       'prevent', 'previous', 'price', 'printf', 'probably', 'problem',\n",
              "       'problems', 'process', 'processing', 'product', 'products',\n",
              "       'professor', 'program', 'programming', 'programs', 'project',\n",
              "       'provide', 'provided', 'provides', 'pub', 'public', 'published',\n",
              "       'purpose', 'quality', 'question', 'questions', 'quite', 'r5',\n",
              "       'radio', 'range', 'rate', 'ray', 'read', 'reading', 'real',\n",
              "       'really', 'reason', 'reasonable', 'reasons', 'receive', 'received',\n",
              "       'recent', 'recently', 'red', 'reference', 'references',\n",
              "       'regarding', 'related', 'release', 'religion', 'religious',\n",
              "       'remember', 'remote', 'reply', 'report', 'reported', 'reports',\n",
              "       'request', 'require', 'required', 'requires', 'research',\n",
              "       'resource', 'resources', 'response', 'rest', 'result', 'results',\n",
              "       'return', 'ride', 'riding', 'right', 'rights', 'road', 'room',\n",
              "       'rule', 'rules', 'run', 'running', 'runs', 'russian', 'said',\n",
              "       'san', 'save', 'saw', 'say', 'saying', 'says', 'school', 'science',\n",
              "       'scientific', 'screen', 'scripture', 'search', 'season', 'second',\n",
              "       'section', 'seen', 'self', 'send', 'sense', 'sent', 'serdar',\n",
              "       'serdar argic', 'series', 'server', 'service', 'set', 'setting',\n",
              "       'sex', 'sgi', 'shall', 'shell', 'short', 'shows', 'signal',\n",
              "       'similar', 'simple', 'simply', 'sin', 'single', 'site', 'sites',\n",
              "       'situation', 'size', 'small', 'society', 'software', 'soldiers',\n",
              "       'solution', 'son', 'soon', 'sorry', 'sort', 'sound', 'sounds',\n",
              "       'source', 'sources', 'soviet', 'space', 'speak', 'special',\n",
              "       'specific', 'speed', 'spirit', 'st', 'standard', 'start',\n",
              "       'started', 'starting', 'state', 'statement', 'states', 'stay',\n",
              "       'steve', 'stop', 'story', 'street', 'string', 'strong', 'studies',\n",
              "       'study', 'stuff', 'subject', 'suggest', 'suggestions', 'sun',\n",
              "       'support', 'supported', 'supports', 'sure', 'systems', 'table',\n",
              "       'taken', 'takes', 'taking', 'talk', 'talking', 'tape', 'tar',\n",
              "       'team', 'technology', 'tell', 'term', 'terms', 'test', 'text',\n",
              "       'thank', 'thanks', 'thanks advance', 'theory', 'thing', 'things',\n",
              "       'think', 'thinking', 'thought', 'tiff', 'time', 'times', 'title',\n",
              "       'today', 'told', 'took', 'tool', 'toolkit', 'tools', 'total',\n",
              "       'town', 'treatment', 'tried', 'troops', 'trouble', 'true', 'truth',\n",
              "       'try', 'trying', 'turkey', 'turkish', 'turks', 'turn', 'turned',\n",
              "       'tv', 'type', 'types', 'uk', 'understand', 'understanding',\n",
              "       'unfortunately', 'united', 'united states', 'university', 'unix',\n",
              "       'unless', 'use', 'used', 'useful', 'usenet', 'user', 'users',\n",
              "       'uses', 'using', 'usr', 'usually', 'value', 'values', 'various',\n",
              "       've', 'version', 'versions', 'video', 'view', 'village',\n",
              "       'villages', 'visual', 'vitamin', 'volume', 'want', 'wanted',\n",
              "       'wants', 'war', 'washington', 'wasn', 'water', 'way', 'ways',\n",
              "       'week', 'weeks', 'went', 'west', 'western', 'white', 'widget',\n",
              "       'widgets', 'wife', 'willing', 'win', 'window', 'window manager',\n",
              "       'windows', 'wire', 'wish', 'woman', 'women', 'won', 'wondering',\n",
              "       'word', 'words', 'work', 'worked', 'working', 'works', 'world',\n",
              "       'worth', 'wouldn', 'write', 'writing', 'written', 'wrong', 'wrote',\n",
              "       'x11', 'x11r5', 'xlib', 'xt', 'xterm', 'xv', 'xview', 'year',\n",
              "       'years', 'years ago', 'yes', 'york', 'young'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LDA 객체 생성 후 Count 피처 벡터화 객체로 LDA수행\n",
        "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
        "lda.fit(feat_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "EoMkmrE7OCj4",
        "outputId": "11cdf0f9-a66f-4c9f-d45d-65fe5aa7702c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=8, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=8, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=8, random_state=0)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 토픽 모델링 주제별 단어들의 연관도 확인\n",
        "#lda객체의 components_ 속성은 주제별로 개별 단어들의 연관도 정규화 숫자가 들어있음\n",
        "#shape는 주제 개수 X 피처 단어 개수\n",
        "#components_ 에 들어 있는 숫자값은 각 주제별로 단어가 나타난 횟수를 정규화 하여 나타냄.\n",
        "#숫자가 클 수록 토픽에서 단어가 차지하는 비중이 높음\n",
        "\n",
        "print(lda.components_.shape)\n",
        "lda.components_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIUracL1OHkn",
        "outputId": "de3bfd58-71cb-4672-ad29-9d2ac9bbc49b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 1000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.69030238e+02, 1.87798026e+02, 7.09003824e+01, ...,\n",
              "        1.22710343e+01, 1.06329639e+02, 7.25995512e+01],\n",
              "       [1.25091799e-01, 2.46049106e+00, 1.25051902e-01, ...,\n",
              "        2.80071176e+02, 1.25089783e-01, 5.05669662e+01],\n",
              "       [1.33978420e+02, 1.25042012e-01, 9.98277256e+01, ...,\n",
              "        1.25092219e-01, 3.31078261e+01, 1.25028398e-01],\n",
              "       ...,\n",
              "       [2.98813886e+01, 1.88071366e+01, 1.14748730e+01, ...,\n",
              "        1.93022584e+01, 5.29368271e+00, 1.44478198e+01],\n",
              "       [1.25074899e-01, 1.25105300e-01, 1.25004235e-01, ...,\n",
              "        1.03576436e+02, 1.25100535e-01, 7.22276359e+01],\n",
              "       [1.25172284e-01, 1.03967760e+00, 1.25221075e-01, ...,\n",
              "        5.31740996e+01, 1.25025929e-01, 1.25062991e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topic_words(model, feature_names, no_top_words):\n",
        "    for topic_index, topic in enumerate(model.components_):\n",
        "        print('\\nTopic #',topic_index)\n",
        "\n",
        "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array index를 반환.\n",
        "        topic_word_indexes = topic.argsort()[::-1]\n",
        "        top_indexes=topic_word_indexes[:no_top_words]\n",
        "\n",
        "        # top_indexes대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
        "        feature_concat = ' '.join([str(feature_names[i]) for i in top_indexes])\n",
        "        #feature_concat = ' + '.join([str(feature_names[i])+'*'+str(round(topic[i],1)) for i in top_indexes])\n",
        "        print(feature_concat)\n",
        "\n",
        "# CountVectorizer객체내의 전체 word들의 명칭을 get_features_names( )를 통해 추출\n",
        "feature_names = count_vect.get_feature_names_out()\n",
        "\n",
        "# Topic별 가장 연관도가 높은 word를 15개만 추출\n",
        "display_topic_words(lda, feature_names, 15)\n",
        "\n",
        "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 등 8개 주제를 추출."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpFWUSjiOO45",
        "outputId": "2f6878e4-fb64-41e7-d14a-61da2ad5e89c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic # 0\n",
            "10 year medical health 1993 20 12 disease cancer team patients research number new 11\n",
            "\n",
            "Topic # 1\n",
            "don just like know think good time ve does way really people want ll right\n",
            "\n",
            "Topic # 2\n",
            "image file jpeg output program gif images format files color entry use bit 03 02\n",
            "\n",
            "Topic # 3\n",
            "armenian armenians turkish people said turkey armenia government genocide turks muslim russian greek azerbaijan killed\n",
            "\n",
            "Topic # 4\n",
            "israel jews dos jewish israeli dos dos arab state people arabs palestinian adl ed anti peace\n",
            "\n",
            "Topic # 5\n",
            "edu com available graphics ftp window use mail data motif software version pub information server\n",
            "\n",
            "Topic # 6\n",
            "god people jesus church believe say christ does christian think christians did know bible man\n",
            "\n",
            "Topic # 7\n",
            "thanks use using does help like display need problem know server screen windows window program\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  개별 문서별 토픽 분포 확인\n",
        "# lda객체의 transform()을 수행하면 개별 문서별 토픽 분포를 반환함.\n",
        "\n",
        "doc_topics = lda.transform(feat_vect)\n",
        "print(doc_topics.shape)\n",
        "print(doc_topics[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z7KCk9JOfUz",
        "outputId": "2e1c5414-a1d6-461a-9f86-53b72d147786"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7862, 8)\n",
            "[[0.01389159 0.4167286  0.01389166 0.01394463 0.01389457 0.01389782\n",
            "  0.01392313 0.49982799]\n",
            " [0.3807043  0.60656453 0.00212172 0.00212189 0.00212118 0.00212221\n",
            "  0.00212166 0.00212251]\n",
            " [0.00544098 0.71518021 0.25216591 0.00543855 0.00544206 0.00544487\n",
            "  0.00543991 0.00544752]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 개별 문서별 토픽 분포도를 출력\n",
        "# 20newsgroup으로 만들어진 문서명을 출력.\n",
        "# fetch_20newsgroups()으로 만들어진 데이터의 filename속성은 모든 문서의 문서명을 가지고 있음.\n",
        "# filename속성은 절대 디렉토리를 가지는 문서명을 가지고 있으므로 '\\'로 분할하여 맨 마지막 두번째 부터 파일명으로 가져옴\n",
        "\n",
        "def get_filename_list(newsdata):\n",
        "    filename_list=[]\n",
        "\n",
        "    for file in newsdata.filenames:\n",
        "            #print(file)\n",
        "            filename_temp = file.split('\\\\')[-2:]\n",
        "            filename = '.'.join(filename_temp)\n",
        "            filename_list.append(filename)\n",
        "\n",
        "    return filename_list\n",
        "\n",
        "filename_list = get_filename_list(news_df)\n",
        "print(\"filename 개수:\",len(filename_list), \"filename list 10개만:\",filename_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2IZOAC5Ouu8",
        "outputId": "c3f11777-0872-47f3-d149-e47c3e214205"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename 개수: 7862 filename list 10개만: ['/root/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20630', '/root/scikit_learn_data/20news_home/20news-bydate-test/sci.med/59422', '/root/scikit_learn_data/20news_home/20news-bydate-test/comp.graphics/38765', '/root/scikit_learn_data/20news_home/20news-bydate-test/comp.graphics/38810', '/root/scikit_learn_data/20news_home/20news-bydate-test/sci.med/59449', '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38461', '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.windows.x/66959', '/root/scikit_learn_data/20news_home/20news-bydate-train/rec.motorcycles/104487', '/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/53875', '/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/53617']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df.filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgyyu9bgO4Hz",
        "outputId": "40b7d991-ecf8-4024-9f2a-d19db107cfdc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/root/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20630',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-test/sci.med/59422',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-test/comp.graphics/38765',\n",
              "       ...,\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.baseball/102656',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/53606',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.mideast/76505'],\n",
              "      dtype='<U86')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame으로 생성하여 문서별 토픽 분포도 확인\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "topic_names = ['Topic #'+ str(i) for i in range(0, 8)]\n",
        "doc_topic_df = pd.DataFrame(data=doc_topics, columns=topic_names, index=filename_list)\n",
        "doc_topic_df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d10i6hbXO6OX",
        "outputId": "584a1840-9b69-4c21-f090-b11ef908021d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    Topic #0  Topic #1  \\\n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.013892  0.416729   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.380704  0.606565   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.005441  0.715180   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.005440  0.437354   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.006583  0.891476   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.008341  0.762012   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.399332  0.041667   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.203226  0.767906   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.008950  0.937410   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.041713  0.041737   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.001646  0.685098   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.850304  0.145805   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.198810  0.673160   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.040335  0.199372   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.017883  0.874918   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.003382  0.693759   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.304974  0.295356   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.015640  0.595612   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.002454  0.113047   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.000080  0.037667   \n",
              "\n",
              "                                                    Topic #2  Topic #3  \\\n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.013892  0.013945   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.002122  0.002122   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.252166  0.005439   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.005449  0.005440   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.068998  0.006592   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.187925  0.008335   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.350541  0.041694   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.004813  0.004811   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.008931  0.008944   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.708129  0.041675   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.001647  0.001646   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.000649  0.000648   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.007372  0.091190   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.377360  0.003910   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.017864  0.017865   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.003382  0.003380   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.003474  0.382294   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.015636  0.015634   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.002454  0.232427   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.928581  0.000080   \n",
              "\n",
              "                                                    Topic #4  Topic #5  \\\n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.013895  0.013898   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.002121  0.002122   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.005442  0.005445   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.005443  0.529984   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.006589  0.006589   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.008339  0.008344   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.041675  0.041701   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.004812  0.004810   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.008937  0.008961   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.041671  0.041670   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.001646  0.001649   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.000648  0.000648   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.007369  0.007371   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.003910  0.003912   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.017864  0.017861   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.285949  0.003381   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.003475  0.003474   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.015638  0.310551   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.002456  0.002453   \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.000080  0.033351   \n",
              "\n",
              "                                                    Topic #6  Topic #7  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.013923  0.499828  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.002122  0.002123  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.005440  0.005448  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.005445  0.005444  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.006589  0.006585  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.008344  0.008359  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.041667  0.041724  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.004812  0.004810  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.008932  0.008935  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.041705  0.041700  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.001647  0.305022  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.000649  0.000649  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.007366  0.007362  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.003912  0.367291  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.017874  0.017871  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.003384  0.003382  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.003476  0.003475  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.015642  0.015647  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.574023  0.070686  \n",
              "/root/scikit_learn_data/20news_home/20news-byda...  0.000080  0.000080  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a9eae48-84df-46e8-a4e2-f45efdd83c48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic #0</th>\n",
              "      <th>Topic #1</th>\n",
              "      <th>Topic #2</th>\n",
              "      <th>Topic #3</th>\n",
              "      <th>Topic #4</th>\n",
              "      <th>Topic #5</th>\n",
              "      <th>Topic #6</th>\n",
              "      <th>Topic #7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20630</th>\n",
              "      <td>0.013892</td>\n",
              "      <td>0.416729</td>\n",
              "      <td>0.013892</td>\n",
              "      <td>0.013945</td>\n",
              "      <td>0.013895</td>\n",
              "      <td>0.013898</td>\n",
              "      <td>0.013923</td>\n",
              "      <td>0.499828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/sci.med/59422</th>\n",
              "      <td>0.380704</td>\n",
              "      <td>0.606565</td>\n",
              "      <td>0.002122</td>\n",
              "      <td>0.002122</td>\n",
              "      <td>0.002121</td>\n",
              "      <td>0.002122</td>\n",
              "      <td>0.002122</td>\n",
              "      <td>0.002123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/comp.graphics/38765</th>\n",
              "      <td>0.005441</td>\n",
              "      <td>0.715180</td>\n",
              "      <td>0.252166</td>\n",
              "      <td>0.005439</td>\n",
              "      <td>0.005442</td>\n",
              "      <td>0.005445</td>\n",
              "      <td>0.005440</td>\n",
              "      <td>0.005448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/comp.graphics/38810</th>\n",
              "      <td>0.005440</td>\n",
              "      <td>0.437354</td>\n",
              "      <td>0.005449</td>\n",
              "      <td>0.005440</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>0.529984</td>\n",
              "      <td>0.005445</td>\n",
              "      <td>0.005444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/sci.med/59449</th>\n",
              "      <td>0.006583</td>\n",
              "      <td>0.891476</td>\n",
              "      <td>0.068998</td>\n",
              "      <td>0.006592</td>\n",
              "      <td>0.006589</td>\n",
              "      <td>0.006589</td>\n",
              "      <td>0.006589</td>\n",
              "      <td>0.006585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38461</th>\n",
              "      <td>0.008341</td>\n",
              "      <td>0.762012</td>\n",
              "      <td>0.187925</td>\n",
              "      <td>0.008335</td>\n",
              "      <td>0.008339</td>\n",
              "      <td>0.008344</td>\n",
              "      <td>0.008344</td>\n",
              "      <td>0.008359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/comp.windows.x/66959</th>\n",
              "      <td>0.399332</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.350541</td>\n",
              "      <td>0.041694</td>\n",
              "      <td>0.041675</td>\n",
              "      <td>0.041701</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.041724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/rec.motorcycles/104487</th>\n",
              "      <td>0.203226</td>\n",
              "      <td>0.767906</td>\n",
              "      <td>0.004813</td>\n",
              "      <td>0.004811</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>0.004810</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>0.004810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/53875</th>\n",
              "      <td>0.008950</td>\n",
              "      <td>0.937410</td>\n",
              "      <td>0.008931</td>\n",
              "      <td>0.008944</td>\n",
              "      <td>0.008937</td>\n",
              "      <td>0.008961</td>\n",
              "      <td>0.008932</td>\n",
              "      <td>0.008935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/53617</th>\n",
              "      <td>0.041713</td>\n",
              "      <td>0.041737</td>\n",
              "      <td>0.708129</td>\n",
              "      <td>0.041675</td>\n",
              "      <td>0.041671</td>\n",
              "      <td>0.041670</td>\n",
              "      <td>0.041705</td>\n",
              "      <td>0.041700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/sci.electronics/54089</th>\n",
              "      <td>0.001646</td>\n",
              "      <td>0.685098</td>\n",
              "      <td>0.001647</td>\n",
              "      <td>0.001646</td>\n",
              "      <td>0.001646</td>\n",
              "      <td>0.001649</td>\n",
              "      <td>0.001647</td>\n",
              "      <td>0.305022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.baseball/102713</th>\n",
              "      <td>0.850304</td>\n",
              "      <td>0.145805</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>0.000649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/rec.sport.baseball/104711</th>\n",
              "      <td>0.198810</td>\n",
              "      <td>0.673160</td>\n",
              "      <td>0.007372</td>\n",
              "      <td>0.091190</td>\n",
              "      <td>0.007369</td>\n",
              "      <td>0.007371</td>\n",
              "      <td>0.007366</td>\n",
              "      <td>0.007362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38232</th>\n",
              "      <td>0.040335</td>\n",
              "      <td>0.199372</td>\n",
              "      <td>0.377360</td>\n",
              "      <td>0.003910</td>\n",
              "      <td>0.003910</td>\n",
              "      <td>0.003912</td>\n",
              "      <td>0.003912</td>\n",
              "      <td>0.367291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/52732</th>\n",
              "      <td>0.017883</td>\n",
              "      <td>0.874918</td>\n",
              "      <td>0.017864</td>\n",
              "      <td>0.017865</td>\n",
              "      <td>0.017864</td>\n",
              "      <td>0.017861</td>\n",
              "      <td>0.017874</td>\n",
              "      <td>0.017871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/talk.politics.mideast/76440</th>\n",
              "      <td>0.003382</td>\n",
              "      <td>0.693759</td>\n",
              "      <td>0.003382</td>\n",
              "      <td>0.003380</td>\n",
              "      <td>0.285949</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>0.003384</td>\n",
              "      <td>0.003382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/sci.med/59243</th>\n",
              "      <td>0.304974</td>\n",
              "      <td>0.295356</td>\n",
              "      <td>0.003474</td>\n",
              "      <td>0.382294</td>\n",
              "      <td>0.003475</td>\n",
              "      <td>0.003474</td>\n",
              "      <td>0.003476</td>\n",
              "      <td>0.003475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.mideast/75888</th>\n",
              "      <td>0.015640</td>\n",
              "      <td>0.595612</td>\n",
              "      <td>0.015636</td>\n",
              "      <td>0.015634</td>\n",
              "      <td>0.015638</td>\n",
              "      <td>0.310551</td>\n",
              "      <td>0.015642</td>\n",
              "      <td>0.015647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-test/soc.religion.christian/21526</th>\n",
              "      <td>0.002454</td>\n",
              "      <td>0.113047</td>\n",
              "      <td>0.002454</td>\n",
              "      <td>0.232427</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.002453</td>\n",
              "      <td>0.574023</td>\n",
              "      <td>0.070686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/root/scikit_learn_data/20news_home/20news-bydate-train/comp.windows.x/66408</th>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.037667</td>\n",
              "      <td>0.928581</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.033351</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.000080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a9eae48-84df-46e8-a4e2-f45efdd83c48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a9eae48-84df-46e8-a4e2-f45efdd83c48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a9eae48-84df-46e8-a4e2-f45efdd83c48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e33dc6d4-7b2f-4a0b-be6b-6120a47bcd63\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e33dc6d4-7b2f-4a0b-be6b-6120a47bcd63')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e33dc6d4-7b2f-4a0b-be6b-6120a47bcd63 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "doc_topic_df",
              "summary": "{\n  \"name\": \"doc_topic_df\",\n  \"rows\": 7862,\n  \"fields\": [\n    {\n      \"column\": \"Topic #0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17271117783372494,\n        \"min\": 3.84619885503318e-05,\n        \"max\": 0.9992575108073914,\n        \"num_unique_values\": 7522,\n        \"samples\": [\n          0.04167895577722352,\n          0.006261963978887043,\n          0.0034776001916584664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic #1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33220083646033727,\n        \"min\": 3.8428546423096724e-05,\n        \"max\": 0.992030240408646,\n        \"num_unique_values\": 7522,\n        \"samples\": [\n          0.7079378462659504,\n          0.9043363047918928,\n          0.372485966872398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic #2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1226069987133065,\n        \"min\": 3.847978030811547e-05,\n        \"max\": 0.9994758790236961,\n        \"num_unique_values\": 7522,\n        \"samples\": [\n          0.04169556707745499,\n          0.006252787674255246,\n          0.0034765263638711135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic #3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14538772751183796,\n        \"min\": 3.842853882553015e-05,\n        \"max\": 0.9985020042226662,\n        \"num_unique_values\": 7522,\n        \"samples\": [\n          0.04171643515576038,\n          0.058126924656854255,\n          0.003473963231220428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic #4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14487906153205235,\n        \"min\": 4.0217971408889245e-05,\n        \"max\": 0.9867294552926111,\n        \"num_unique_values\": 7522,\n        \"samples\": [\n          0.04173999799776256,\n          0.0062569613749740875,\n          0.003473935081475321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic #5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19913226656140845,\n        \"min\": 5.5929572220507664e-05,\n        \"max\": 0.9996445441103418,\n        \"num_unique_values\": 7522,\n        \"samples\": [\n          0.04169495564609356,\n          0.006252939253513428,\n          0.0777536604204739\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic #6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.256712603776007,\n        \"min\": 3.842451843200172e-05,\n        \"max\": 0.9981668519515128,\n        \"num_unique_values\": 7522,\n        \"samples\": [\n          0.04175334356924003,\n          0.006256006307929344,\n          0.0034751625602905773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic #7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2512419337335072,\n        \"min\": 4.4466371735472344e-05,\n        \"max\": 0.9878287849563636,\n        \"num_unique_values\": 7522,\n        \"samples\": [\n          0.041782898510514734,\n          0.006256111961693688,\n          0.5323831852786121\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}